import cv2
import math
import numpy as np
import os
import os.path as osp
import random
import time
import torch
from pathlib import Path
from torch.utils import data as data
import pandas as pd
import pickle

from basicsr.data.degradations import circular_lowpass_kernel, random_mixed_kernels
from basicsr.data.transforms import augment
from basicsr.utils import FileClient, get_root_logger, imfrombytes, img2tensor
from basicsr.utils.registry import DATASET_REGISTRY
import warnings

@DATASET_REGISTRY.register(suffix='basicsr')
class RealESRGANDataset(data.Dataset):
    """Modified dataset based on the dataset used for Real-ESRGAN model:
    Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data.

    It loads gt (Ground-Truth) images, and augments them.
    It also generates blur kernels and sinc kernels for generating low-quality images.
    Note that the low-quality images are processed in tensors on GPUS for faster processing.

    Args:
        opt (dict): Config for train datasets. It contains the following keys:
            dataroot_gt (str): Data root path for gt.
            meta_info (str): Path for meta information file.
            io_backend (dict): IO backend type and other kwarg.
            use_hflip (bool): Use horizontal flips.
            use_rot (bool): Use rotation (use vertical flip and transposing h and w for implementation).
            Please see more options in the codes.
    """

    def __init__(self, opt):
        super(RealESRGANDataset, self).__init__()
        self.opt = opt
        self.file_client = None
        self.io_backend_opt = opt['io_backend']
        if 'crop_size' in opt:
            self.crop_size = opt['crop_size']
        else:
            self.crop_size = 512
        if 'image_type' not in opt:
            opt['image_type'] = 'png'

        # support multiple type of data: file path and meta data, remove support of lmdb
        self.paths = []
        if 'meta_info' in opt:
            with open(self.opt['meta_info']) as fin:
                    paths = [line.strip().split(' ')[0] for line in fin]
                    self.paths = [v for v in paths]
            if 'meta_num' in opt:
                self.paths = sorted(self.paths)[:opt['meta_num']]
        if 'gt_path' in opt:
            if isinstance(opt['gt_path'], str):
                self.paths.extend(sorted([str(x) for x in Path(opt['gt_path']).glob('*.'+opt['image_type'])]))
            else:
                self.paths.extend(sorted([str(x) for x in Path(opt['gt_path'][0]).glob('*.'+opt['image_type'])]))
                if len(opt['gt_path']) > 1:
                    for i in range(len(opt['gt_path'])-1):
                        self.paths.extend(sorted([str(x) for x in Path(opt['gt_path'][i+1]).glob('*.'+opt['image_type'])]))
        if 'imagenet_path' in opt:
            class_list = os.listdir(opt['imagenet_path'])
            for class_file in class_list:
                self.paths.extend(sorted([str(x) for x in Path(os.path.join(opt['imagenet_path'], class_file)).glob('*.'+'JPEG')]))
        if 'face_gt_path' in opt:
            if isinstance(opt['face_gt_path'], str):
                face_list = sorted([str(x) for x in Path(opt['face_gt_path']).glob('*.'+opt['image_type'])])
                self.paths.extend(face_list[:opt['num_face']])
            else:
                face_list = sorted([str(x) for x in Path(opt['face_gt_path'][0]).glob('*.'+opt['image_type'])])
                self.paths.extend(face_list[:opt['num_face']])
                if len(opt['face_gt_path']) > 1:
                    for i in range(len(opt['face_gt_path'])-1):
                        self.paths.extend(sorted([str(x) for x in Path(opt['face_gt_path'][0]).glob('*.'+opt['image_type'])])[:opt['num_face']])

        # limit number of pictures for test
        if 'num_pic' in opt:
            if 'val' or 'test' in opt:
                random.shuffle(self.paths)
                self.paths = self.paths[:opt['num_pic']]
            else:
                self.paths = self.paths[:opt['num_pic']]

        if 'mul_num' in opt:
            self.paths = self.paths * opt['mul_num']
            # print('>>>>>>>>>>>>>>>>>>>>>')
            # print(self.paths)

        # blur settings for the first degradation
        self.blur_kernel_size = opt['blur_kernel_size']
        self.kernel_list = opt['kernel_list']
        self.kernel_prob = opt['kernel_prob']  # a list for each kernel probability
        self.blur_sigma = opt['blur_sigma']
        self.betag_range = opt['betag_range']  # betag used in generalized Gaussian blur kernels
        self.betap_range = opt['betap_range']  # betap used in plateau blur kernels
        self.sinc_prob = opt['sinc_prob']  # the probability for sinc filters

        # blur settings for the second degradation
        self.blur_kernel_size2 = opt['blur_kernel_size2']
        self.kernel_list2 = opt['kernel_list2']
        self.kernel_prob2 = opt['kernel_prob2']
        self.blur_sigma2 = opt['blur_sigma2']
        self.betag_range2 = opt['betag_range2']
        self.betap_range2 = opt['betap_range2']
        self.sinc_prob2 = opt['sinc_prob2']

        # a final sinc filter
        self.final_sinc_prob = opt['final_sinc_prob']

        self.kernel_range = [2 * v + 1 for v in range(3, 11)]  # kernel size ranges from 7 to 21
        # TODO: kernel range is now hard-coded, should be in the configure file
        self.pulse_tensor = torch.zeros(21, 21).float()  # convolving with pulse tensor brings no blurry effect
        self.pulse_tensor[10, 10] = 1

    def __getitem__(self, index):
        if self.file_client is None:
            # disk
            self.file_client = FileClient(self.io_backend_opt.pop('type'), **self.io_backend_opt)

        # -------------------------------- Load gt images -------------------------------- #
        # Shape: (h, w, c); channel order: BGR; image range: [0, 1], float32.
        gt_path = self.paths[index]
        # avoid errors caused by high latency in reading files
        retry = 3
        while retry > 0:
            try:
                img_bytes = self.file_client.get(gt_path, 'gt')
            except (IOError, OSError) as e:
                # logger = get_root_logger()
                # logger.warn(f'File client error: {e}, remaining retry times: {retry - 1}')
                # change another file to read
                index = random.randint(0, self.__len__()-1)
                gt_path = self.paths[index]
                time.sleep(1)  # sleep 1s for occasional server congestion
            else:
                break
            finally:
                retry -= 1
        img_gt = imfrombytes(img_bytes, float32=True)
        # filter the dataset and remove images with too low quality
        img_size = os.path.getsize(gt_path)
        img_size = img_size/1024

        while img_gt.shape[0] * img_gt.shape[1] < 384*384 or img_size<100:
            index = random.randint(0, self.__len__()-1)
            gt_path = self.paths[index]

            time.sleep(0.1)  # sleep 1s for occasional server congestion
            img_bytes = self.file_client.get(gt_path, 'gt')
            img_gt = imfrombytes(img_bytes, float32=True)
            img_size = os.path.getsize(gt_path)
            img_size = img_size/1024

        # -------------------- Do augmentation for training: flip, rotation -------------------- #
        img_gt = augment(img_gt, self.opt['use_hflip'], self.opt['use_rot'])

        # crop or pad to 400
        # TODO: 400 is hard-coded. You may change it accordingly
        h, w = img_gt.shape[0:2]
        crop_pad_size = self.crop_size
        # pad
        if h < crop_pad_size or w < crop_pad_size:
            pad_h = max(0, crop_pad_size - h)
            pad_w = max(0, crop_pad_size - w)
            img_gt = cv2.copyMakeBorder(img_gt, 0, pad_h, 0, pad_w, cv2.BORDER_REFLECT_101)
        # crop
        if img_gt.shape[0] > crop_pad_size or img_gt.shape[1] > crop_pad_size:
            h, w = img_gt.shape[0:2]
            # randomly choose top and left coordinates
            top = random.randint(0, h - crop_pad_size)
            left = random.randint(0, w - crop_pad_size)
            # top = (h - crop_pad_size) // 2 -1
            # left = (w - crop_pad_size) // 2 -1
            img_gt = img_gt[top:top + crop_pad_size, left:left + crop_pad_size, ...]

        # ------------------------ Generate kernels (used in the first degradation) ------------------------ #
        kernel_size = random.choice(self.kernel_range)
        if np.random.uniform() < self.opt['sinc_prob']:
            # this sinc filter setting is for kernels ranging from [7, 21]
            if kernel_size < 13:
                omega_c = np.random.uniform(np.pi / 3, np.pi)
            else:
                omega_c = np.random.uniform(np.pi / 5, np.pi)
            kernel = circular_lowpass_kernel(omega_c, kernel_size, pad_to=False)
        else:
            kernel = random_mixed_kernels(
                self.kernel_list,
                self.kernel_prob,
                kernel_size,
                self.blur_sigma,
                self.blur_sigma, [-math.pi, math.pi],
                self.betag_range,
                self.betap_range,
                noise_range=None)
        # pad kernel
        pad_size = (21 - kernel_size) // 2
        kernel = np.pad(kernel, ((pad_size, pad_size), (pad_size, pad_size)))

        # ------------------------ Generate kernels (used in the second degradation) ------------------------ #
        kernel_size = random.choice(self.kernel_range)
        if np.random.uniform() < self.opt['sinc_prob2']:
            if kernel_size < 13:
                omega_c = np.random.uniform(np.pi / 3, np.pi)
            else:
                omega_c = np.random.uniform(np.pi / 5, np.pi)
            kernel2 = circular_lowpass_kernel(omega_c, kernel_size, pad_to=False)
        else:
            kernel2 = random_mixed_kernels(
                self.kernel_list2,
                self.kernel_prob2,
                kernel_size,
                self.blur_sigma2,
                self.blur_sigma2, [-math.pi, math.pi],
                self.betag_range2,
                self.betap_range2,
                noise_range=None)

        # pad kernel
        pad_size = (21 - kernel_size) // 2
        kernel2 = np.pad(kernel2, ((pad_size, pad_size), (pad_size, pad_size)))

        # ------------------------------------- the final sinc kernel ------------------------------------- #
        if np.random.uniform() < self.opt['final_sinc_prob']:
            kernel_size = random.choice(self.kernel_range)
            omega_c = np.random.uniform(np.pi / 3, np.pi)
            sinc_kernel = circular_lowpass_kernel(omega_c, kernel_size, pad_to=21)
            sinc_kernel = torch.FloatTensor(sinc_kernel)
        else:
            sinc_kernel = self.pulse_tensor

        # BGR to RGB, HWC to CHW, numpy to tensor
        img_gt = img2tensor([img_gt], bgr2rgb=True, float32=True)[0]
        kernel = torch.FloatTensor(kernel)
        kernel2 = torch.FloatTensor(kernel2)

        return_d = {'gt': img_gt, 'kernel1': kernel, 'kernel2': kernel2, 'sinc_kernel': sinc_kernel, 'gt_path': gt_path}
        return return_d

    def __len__(self):
        return len(self.paths)


@DATASET_REGISTRY.register()
class RealESRGANCapRefDataset(data.Dataset):
    """Modified dataset based on the dataset used for Real-ESRGAN model:
    Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data.

    It loads gt (Ground-Truth) images, and augments them.
    It also generates blur kernels and sinc kernels for generating low-quality images.
    Note that the low-quality images are processed in tensors on GPUS for faster processing.

    Args:
        opt (dict): Config for train datasets. It contains the following keys:
            dataroot_gt (str): Data root path for gt.
            meta_info (str): Path for meta information file.
            io_backend (dict): IO backend type and other kwarg.
            use_hflip (bool): Use horizontal flips.
            use_rot (bool): Use rotation (use vertical flip and transposing h and w for implementation).
            Please see more options in the codes.
    """

    def __init__(self, opt):
        super(RealESRGANCapRefDataset, self).__init__()
        self.opt = opt
        self.file_client = None
        self.io_backend_opt = opt['io_backend']
        if 'crop_size' in opt:
            self.crop_size = opt['crop_size']
        else:
            self.crop_size = 512
        if 'image_type' not in opt:
            opt['image_type'] = 'png'

        # support multiple type of data: file path and meta data, remove support of lmdb
        self.paths = []
        self.seg_paths = []
        self.mask_paths = []
        # if 'meta_info' in opt:
        #     with open(self.opt['meta_info']) as fin:
        #             paths = [line.strip().split(' ')[0] for line in fin]
        #             self.paths = [v for v in paths]
        #     if 'meta_num' in opt:
        #         self.paths = sorted(self.paths)[:opt['meta_num']]
        # if 'gt_path' in opt:
        #     if isinstance(opt['gt_path'], str):
        #         self.paths.extend(sorted([str(x) for x in Path(opt['gt_path']).glob('*.'+opt['image_type'])]))
        #     else:
        #         self.paths.extend(sorted([str(x) for x in Path(opt['gt_path'][0]).glob('*.'+opt['image_type'])]))
        #         if len(opt['gt_path']) > 1:
        #             for i in range(len(opt['gt_path'])-1):
        #                 self.paths.extend(sorted([str(x) for x in Path(opt['gt_path'][i+1]).glob('*.'+opt['image_type'])]))
        if 'imagenet_path' in opt:
            class_list = os.listdir(opt['imagenet_path'])
            for class_file in class_list:
                self.paths.extend(sorted([str(x) for x in Path(os.path.join(opt['imagenet_path'], class_file)).glob('*.'+'JPEG')]))
        if 'face_gt_path' in opt:
            if isinstance(opt['face_gt_path'], str):
                face_list = sorted([str(x) for x in Path(opt['face_gt_path']).glob('*.'+opt['image_type'])])
                self.paths.extend(face_list[:opt['num_face']])
            else:
                face_list = sorted([str(x) for x in Path(opt['face_gt_path'][0]).glob('*.'+opt['image_type'])])
                self.paths.extend(face_list[:opt['num_face']])
                if len(opt['face_gt_path']) > 1:
                    for i in range(len(opt['face_gt_path'])-1):
                        self.paths.extend(sorted([str(x) for x in Path(opt['face_gt_path'][0]).glob('*.'+opt['image_type'])])[:opt['num_face']])

        # limit number of pictures for test
        if 'num_pic' in opt:
            if 'val' or 'test' in opt:
                random.shuffle(self.paths)
                self.paths = self.paths[:opt['num_pic']]
            else:
                self.paths = self.paths[:opt['num_pic']]

        if 'mul_num' in opt:
            self.paths = self.paths * opt['mul_num']
            # print('>>>>>>>>>>>>>>>>>>>>>')
            # print(self.paths)

        # 在原始配置文件中，前面的if条件都不成立，直到这才成立
        if 'meta_info' in opt:
            with open(self.opt['meta_info']) as fin:
                for line in fin.readlines():
                    names = line.rstrip('\n').split('/')
                    self.paths.append(os.path.join(opt['gt_path'], names[0]))
                    now_segs = []
                    now_masks = []
                    for i in range(1,len(names)):
                        now_segs.append(os.path.join(opt['seg_path'], names[i]))
                        last_underscore_index = names[i].rfind('_')
                        mask_name = names[i][:last_underscore_index]+"_mask"+names[i][last_underscore_index:]
                        now_masks.append(os.path.join(opt['mask_path'], mask_name))
                    self.seg_paths.append(now_segs)
                    self.mask_paths.append(now_masks)

        print(f"Total training set size is {len(self.paths)}")

        if 'caption_path' in opt:
            df = pd.read_json(opt['caption_path'])
            df.set_index(["filename"], inplace=True)
            self.caption_df = df
            df = pd.read_table('data/ImageNet/class.txt', sep='\t', header=None)
            df.set_index([1], inplace=True)
            self.class_df = df
            self.use_caption = True
            self.only_class = False
        elif opt['only_class']:
            df = pd.read_table('data/ImageNet/class.txt', sep='\t', header=None)
            df.set_index([1], inplace=True)
            self.class_df = df
            self.use_caption = True
            self.only_class = True
        else:
            self.use_caption = False

        if 'seg_caption_path' in opt:
            df = pd.read_json(opt['seg_caption_path'])
            df.set_index(["filename"], inplace=True)
            self.seg_caption_df = df
        # reference
        with open(opt['reference_path'], 'rb') as f:
            self.reference_sim = pickle.load(f)
        self.reference_select_num = opt['reference_select_num']

        self.drop_rate = opt['drop_rate']
        self.ref_drop_rate = opt['ref_drop_rate'] if 'ref_drop_rate' in opt else 0.0

        # blur settings for the first degradation
        self.blur_kernel_size = opt['blur_kernel_size']
        self.kernel_list = opt['kernel_list']
        self.kernel_prob = opt['kernel_prob']  # a list for each kernel probability
        self.blur_sigma = opt['blur_sigma']
        self.betag_range = opt['betag_range']  # betag used in generalized Gaussian blur kernels
        self.betap_range = opt['betap_range']  # betap used in plateau blur kernels
        self.sinc_prob = opt['sinc_prob']  # the probability for sinc filters

        # blur settings for the second degradation
        self.blur_kernel_size2 = opt['blur_kernel_size2']
        self.kernel_list2 = opt['kernel_list2']
        self.kernel_prob2 = opt['kernel_prob2']
        self.blur_sigma2 = opt['blur_sigma2']
        self.betag_range2 = opt['betag_range2']
        self.betap_range2 = opt['betap_range2']
        self.sinc_prob2 = opt['sinc_prob2']

        # a final sinc filter
        self.final_sinc_prob = opt['final_sinc_prob']

        self.kernel_range = [2 * v + 1 for v in range(3, 11)]  # kernel size ranges from 7 to 21
        # TODO: kernel range is now hard-coded, should be in the configure file
        self.pulse_tensor = torch.zeros(21, 21).float()  # convolving with pulse tensor brings no blurry effect
        self.pulse_tensor[10, 10] = 1

    # 添加了image_class_name的参数，因为分割后的图片的类别写在文件名中
    def generate_caption(self, image_name, image_class_name,clip_thre=0.28, class_name_score=0.5):
        caption_list = []
        prob_list = []
        
        if image_class_name == None:
            caption_data = self.caption_df.loc[image_name]
            class_name = self.class_df.loc[image_name.split('_')[0], 2].replace('_', ' ')
        else:
            caption_data = self.seg_caption_df.loc[image_name]
            class_name = image_class_name
        base_caption = 'a photo of ' + class_name
        caption_list.append(base_caption)
        prob_list.append(class_name_score)

        all_caption = [base_caption]
        all_prob = []

        if caption_data['clip_score1'] >= clip_thre:
            caption_list.append(base_caption + ', ' + caption_data['caption1'])
            all_caption.append(caption_data['caption1'])
            prob_list.append(caption_data['clip_score1'])
            all_prob.append(caption_data['clip_score1'])

        if caption_data['clip_score2'] >= clip_thre:
            caption_list.append(base_caption + ', ' + caption_data['caption2'])
            all_caption.append(caption_data['caption2'])
            prob_list.append(caption_data['clip_score2'])
            all_prob.append(caption_data['clip_score2'])

        if caption_data['clip_score3'] >= clip_thre:
            caption_list.append(base_caption + ', ' + caption_data['caption3'])
            all_caption.append(caption_data['caption3'])
            prob_list.append(caption_data['clip_score3'])
            all_prob.append(caption_data['clip_score3'])

        if all_prob != []:
            caption_list.append(', '.join(all_caption))
            prob_list.append(np.mean(all_prob))

        assert len(caption_list) == len(prob_list)
        prob_list = np.array(prob_list) / np.sum(prob_list)

        return caption_list, prob_list

    def __getitem__(self, index):
        if self.file_client is None:
            self.file_client = FileClient(self.io_backend_opt.pop('type'), **self.io_backend_opt)

        # -------------------------------- Load gt images -------------------------------- #
        # Shape: (h, w, c); channel order: BGR; image range: [0, 1], float32.
        gt_path = self.paths[index]
        seg_paths = self.seg_paths[index]
        mask_paths = self.mask_paths[index]

        # generate caption
        image_name = gt_path.split('/')[-1]
        class_num = image_name.split('_')[0]

        # 在原本的配置文件中,self.use_caption=True
        if self.use_caption and (random.random() > self.drop_rate):
            if not self.only_class:
                caption_list, prob_list = self.generate_caption(image_name,None)
                caption = np.random.choice(caption_list, p=prob_list)
            else:
                class_name = self.class_df.loc[class_num, 2].replace('_', ' ')
                caption = 'a photo of ' + class_name
        else:
            caption = ""

        # generate segments caption
        seg_captions = []
        for seg_path in seg_paths:
            seg_image_name = seg_path.split('/')[-1]
            seg_class_name = seg_image_name.split('_')[2]
            seg_caption_list, seg_pro_list = self.generate_caption(seg_image_name,seg_class_name)
            now_seg_caption = np.random.choice(seg_caption_list,p=seg_pro_list)
            seg_captions.append(now_seg_caption)

        # avoid errors caused by high latency in reading files
        retry = 3
        while retry > 0:
            try:
                img_bytes = self.file_client.get(gt_path, 'gt')
            except (IOError, OSError) as e:
                # logger = get_root_logger()
                # logger.warn(f'File client error: {e}, remaining retry times: {retry - 1}')
                # change another file to read
                index = random.randint(0, self.__len__()-1)
                gt_path = self.paths[index]
                time.sleep(1)  # sleep 1s for occasional server congestion
            else:
                break
            finally:
                retry -= 1
        img_gt = imfrombytes(img_bytes, float32=True)
        # filter the dataset and remove images with too low quality
        img_size = os.path.getsize(gt_path)
        img_size = img_size/1024

        # 读取segments的图片
        img_seg = []
        for now_seg_path in seg_paths:
            now_seg_bytes = self.file_client.get(now_seg_path, 'seg')
            now_img_seg = imfrombytes(now_seg_bytes, float32=True)
            img_seg.append(now_img_seg)

        # 读取mask的图片
        img_mask = []
        for now_mask_path in mask_paths:
            now_mask_bytes = self.file_client.get(now_mask_path, 'mask')
            now_img_mask = imfrombytes(now_mask_bytes, float32=True)
            img_mask.append(now_img_mask)

        if random.random() > self.drop_rate:
            ref_filenames = self.reference_sim[class_num]['filename']
            ref_filenames_numpy = np.array(self.reference_sim[class_num]['filename'])
            ref_self_index = ref_filenames.index(image_name)
            ref_sim = self.reference_sim[class_num]['loss'][ref_self_index]

            ref_filenames_numpy = np.delete(ref_filenames_numpy, [ref_self_index])
            ref_sim = np.delete(ref_sim, [ref_self_index])
            
            sortindex = np.argsort(ref_sim)
            ref_filenames_selected = ref_filenames_numpy[sortindex][-self.reference_select_num:]
            ref_sim_selected = ref_sim[sortindex][-self.reference_select_num:]

            ref_filename_selected = np.random.choice(ref_filenames_selected, p=ref_sim_selected / np.sum(ref_sim_selected))

            img_bytes = self.file_client.get(os.path.join(self.opt['gt_path'], ref_filename_selected), 'gt')
            img_ref = imfrombytes(img_bytes, float32=True)
            img_ref = img2tensor([img_ref], bgr2rgb=True, float32=True)[0]
        else:
            img_ref = np.zeros(img_gt.shape)
            img_ref = img2tensor([img_ref], bgr2rgb=True, float32=True)[0]

        # -------------------- Do augmentation for training: flip, rotation -------------------- #
        # 在这里把配置文件中的use_hflip设置为了False，防止反转。反转后mask就没有意义了
        img_gt = augment(img_gt, self.opt['use_hflip'], self.opt['use_rot'])

        # mask是不是也得做相同的操作?
        # crop or pad to 400
        # TODO: 400 is hard-coded. You may change it accordingly
        h, w = img_gt.shape[0:2]
        crop_pad_size = self.crop_size
        # pad
        if h < crop_pad_size or w < crop_pad_size:
            pad_h = max(0, crop_pad_size - h)
            pad_w = max(0, crop_pad_size - w)
            img_gt = cv2.copyMakeBorder(img_gt, 0, pad_h, 0, pad_w, cv2.BORDER_REFLECT_101)
            for i in range(len(img_mask)):
                img_mask[i] = cv2.copyMakeBorder(img_mask[i], 0, pad_h, 0, pad_w, cv2.BORDER_REFLECT_101)
        # crop
        if img_gt.shape[0] > crop_pad_size or img_gt.shape[1] > crop_pad_size:
            h, w = img_gt.shape[0:2]
            # randomly choose top and left coordinates
            top = random.randint(0, h - crop_pad_size)
            left = random.randint(0, w - crop_pad_size)
            # top = (h - crop_pad_size) // 2 -1
            # left = (w - crop_pad_size) // 2 -1
            img_gt = img_gt[top:top + crop_pad_size, left:left + crop_pad_size, ...]
            for i in range(len(img_mask)):
                img_mask[i] = img_mask[i][top:top + crop_pad_size, left:left + crop_pad_size, ...]

        # ------------------------ Generate kernels (used in the first degradation) ------------------------ #
        kernel_size = random.choice(self.kernel_range)
        if np.random.uniform() < self.opt['sinc_prob']:
            # this sinc filter setting is for kernels ranging from [7, 21]
            if kernel_size < 13:
                omega_c = np.random.uniform(np.pi / 3, np.pi)
            else:
                omega_c = np.random.uniform(np.pi / 5, np.pi)
            kernel = circular_lowpass_kernel(omega_c, kernel_size, pad_to=False)
        else:
            kernel = random_mixed_kernels(
                self.kernel_list,
                self.kernel_prob,
                kernel_size,
                self.blur_sigma,
                self.blur_sigma, [-math.pi, math.pi],
                self.betag_range,
                self.betap_range,
                noise_range=None)
        # pad kernel
        pad_size = (21 - kernel_size) // 2
        kernel = np.pad(kernel, ((pad_size, pad_size), (pad_size, pad_size)))

        # ------------------------ Generate kernels (used in the second degradation) ------------------------ #
        kernel_size = random.choice(self.kernel_range)
        if np.random.uniform() < self.opt['sinc_prob2']:
            if kernel_size < 13:
                omega_c = np.random.uniform(np.pi / 3, np.pi)
            else:
                omega_c = np.random.uniform(np.pi / 5, np.pi)
            kernel2 = circular_lowpass_kernel(omega_c, kernel_size, pad_to=False)
        else:
            kernel2 = random_mixed_kernels(
                self.kernel_list2,
                self.kernel_prob2,
                kernel_size,
                self.blur_sigma2,
                self.blur_sigma2, [-math.pi, math.pi],
                self.betag_range2,
                self.betap_range2,
                noise_range=None)

        # pad kernel
        pad_size = (21 - kernel_size) // 2
        kernel2 = np.pad(kernel2, ((pad_size, pad_size), (pad_size, pad_size)))

        # ------------------------------------- the final sinc kernel ------------------------------------- #
        if np.random.uniform() < self.opt['final_sinc_prob']:
            kernel_size = random.choice(self.kernel_range)
            omega_c = np.random.uniform(np.pi / 3, np.pi)
            sinc_kernel = circular_lowpass_kernel(omega_c, kernel_size, pad_to=21)
            sinc_kernel = torch.FloatTensor(sinc_kernel)
        else:
            sinc_kernel = self.pulse_tensor

        # BGR to RGB, HWC to CHW, numpy to tensor
        img_gt = img2tensor([img_gt], bgr2rgb=True, float32=True)[0]
        kernel = torch.FloatTensor(kernel)
        kernel2 = torch.FloatTensor(kernel2)

        for i in range(len(img_seg)):
            img_seg[i] = img2tensor([img_seg[i]], bgr2rgb=True, float32=True)[0]
        for i in range(len(img_mask)):
            img_mask[i] = img2tensor([img_mask[i]], bgr2rgb=True, float32=True)[0]

        # 把seg和mask的列表长度统一
        
        max_len = 10
        seg_num = torch.tensor(len(img_seg) if len(img_seg)<max_len else max_len)
        # 对 img_seg 进行处理
        img_seg = img_seg[:max_len] + [torch.zeros_like(img_seg[0])] * (max_len - len(img_seg)) if len(img_seg) < max_len else img_seg[:max_len]
        img_seg = torch.stack(img_seg)

        # 对 img_mask 进行处理
        img_mask = img_mask[:max_len] + [torch.zeros_like(img_mask[0])] * (max_len - len(img_mask)) if len(img_mask) < max_len else img_mask[:max_len]
        img_mask = torch.stack(img_mask)

        # 对 seg_paths 进行处理
        seg_paths = seg_paths[:max_len] + [''] * (max_len - len(seg_paths)) if len(seg_paths) < max_len else seg_paths[:max_len]

        # 对 mask_paths 进行处理
        mask_paths = mask_paths[:max_len] + [''] * (max_len - len(mask_paths)) if len(mask_paths) < max_len else mask_paths[:max_len]

        # 对 seg_captions 进行处理
        seg_captions = seg_captions[:max_len] + [''] * (max_len - len(seg_captions)) if len(seg_captions) < max_len else seg_captions[:max_len]

        return_d = {'gt': img_gt, 'segs': img_seg, 'masks':img_mask, 'segs_num':seg_num, 'kernel1': kernel, 'kernel2': kernel2, 'sinc_kernel': sinc_kernel, 
                    'gt_path': gt_path, 'segs_path': seg_paths, 'masks_path': mask_paths ,'caption': caption, 'seg_captions': seg_captions,'ref': img_ref}
        return return_d

    def __len__(self):
        return len(self.paths)
